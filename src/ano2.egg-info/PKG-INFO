Metadata-Version: 2.4
Name: ano2
Version: 0.1.0
Summary: Dynamic feedback categorization pipeline (Category/Subcategory/Sentiment) with API and local vLLM modes
Author: ANO2
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: fastapi>=0.110.0
Requires-Dist: uvicorn>=0.24.0
Requires-Dist: pydantic>=2.7.0
Requires-Dist: PyYAML>=6.0.1
Requires-Dist: httpx>=0.27.0
Requires-Dist: pandas>=2.2.0
Requires-Dist: numpy>=1.26.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: sentence-transformers>=3.0.0
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: typer>=0.12.0

# ANO2 – Pipeline de Catégorisation de Feedback

Pipeline schema-agnostic pour catégoriser des feedbacks en trois colonnes: `Category`, `Sub Category`, `Sentiment` (positif ou négatif), sans taxonomie prédéfinie. La consolidation des catégories sémantiquement proches est réalisée via embeddings + clustering (pas de saturation de contexte). Deux modes LLM: `api` (provider OpenAI‑compatible) et `local` (serveur vLLM OpenAI‑compatible).

## Prérequis
- Python 3.10+
- uv (gestionnaire de paquets Python)
- Variables d'environnement: voir `.env.exemple`

## Installation
```bash
uv sync
```

## Configuration
Modifiez `config/pipeline.example.yaml` selon votre source de données:
- `io.path`: chemin du CSV (ou JSONL si `io.type: jsonl`)
- `io.text_field`: colonne contenant le texte du feedback
- `io.output_path`: chemin du CSV de sortie

LLM via variables d'environnement (exemple dans `.env.exemple`):
- `LLM_MODE=api|local`
- `OPENAI_BASE_URL` (ex: `http://localhost:8000/v1` pour vLLM)
- `OPENAI_API_KEY` (requis pour `api`)
- `LLM_MODEL` (ex: `gpt-4.1` ou modèle local)

## Exécution en local (CLI)
```bash
uv run ano2 run -c config/pipeline.example.yaml
```
Résultat: ajoute les colonnes `Category`, `Sub Category`, `Sentiment` et sauvegarde le CSV si `output_path` est défini.

## API (FastAPI)
Lancement rapide:
```bash
export PIPELINE_CONFIG=config/pipeline.example.yaml
uv run uvicorn ano2.server:app --reload --host 0.0.0.0 --port 8080
```

Exemple d’app (intégration dans votre code):
```python
from ano2.config import PipelineConfig
from ano2.api import create_app

cfg = PipelineConfig.from_yaml("config/pipeline.example.yaml")
app = create_app(cfg)
```
Endpoints:
- `GET /healthz`
- `POST /categorize` avec body `{ "items": [{"id": "1", "text": "..."}] }`

## Notes de conception
- Pas de fallback implicite: en cas de sortie LLM invalide, l'erreur est explicite
- Consolidation par embeddings (multilingue) + agglomératif (seuils configurables)
- Traitement séquentiel par défaut (évite les races)
- Logs concis et utiles (niveau via `LOG_LEVEL`)

## Change Log
- 2025-04-27: Removed the `departement` and `resume` columns from `data/tickets_jira.csv` to align the dataset with current requirements.
