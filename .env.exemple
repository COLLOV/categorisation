#############################################
# LLM provider
#############################################
LLM_MODE=api               # api | local (pour vLLM)
# Pour vLLM local par ex.: OPENAI_BASE_URL=http://localhost:8000/v1
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=key         # clé API (si mode api)
LLM_MODEL=gpt-4.1          # nom du modèle

#############################################
# JSON: strict vs. tolérant
#############################################
# Strict: la réponse DOIT être un objet JSON valide
LLM_STRICT_JSON=1          # 1=strict (prod recommandé), 0=tolérant (dev)
# Si supporté par le provider (OpenAI, etc.), force un JSON côté modèle
LLM_JSON_MODE=0            # 1=active response_format: {type: json_object}

#############################################
# Budgets & robustesse requêtes
#############################################
# Timeout HTTP en secondes
LLM_HTTP_TIMEOUT=60
# Limite tokens de sortie (0 = valeur par défaut du provider)
LLM_MAX_TOKENS=0
# Retries si JSON invalide (en mode strict), avec rappel correctif
LLM_MAX_RETRIES=1
LLM_RETRY_INVALID_JSON=1

#############################################
# Règles extraction mots‑clés
#############################################
# Uniquement des mots simples (pas de phrases / noms composés)
KEYWORDS_SINGLE_WORDS_ONLY=1
# Doit être présent dans le texte source
KEYWORDS_ENFORCE_IN_TEXT=1
# Retirer les termes génériques (issue, problem, application, utilisateur, ...)
KEYWORDS_DROP_GENERIC=1
# Longueur minimale (après normalisation)
KEYWORDS_MIN_LENGTH=2
